# DBOpt_Course_PaymentData
Задание к курсу Оптимизация баз данных - расчёт балансов


В силу условий программного обеспечения, а именно операционной системы Linux, у нас не было возможности использовать напрямую инструменты взаимодействия с MS SQL Server. Поэтому сам SQL Server был поднять с помощью официального [image с dockerhub](https://hub.docker.com/_/microsoft-mssql-server), а для взаимодействия с СУБД применялся python, DataGrip и Azure Data Studio, VSCode с раширением SQL Server, а также pyodbc модуль который предоставляюет интерфейс для доступа к БД на языке Python.

Все замеры в текущей работе были усреднены по нескольким запускам.

## Начальные действия
### Разработать и применить генератор тестовых данных

Генератор был реализован на языке Python (основной класс для генерации находится в файле `sql_adapter.py`) c использованием нативных модулей языка Python, а также библиотеки [Faker](https://github.com/joke2k/faker). Данный пакет позволяет сгенерировать данные более приближенные к действительности. Чтобы сгенерированные данные удовлетворяли всем ограничениям, данный процесс был выполнен в следующем порядке:
- Была сгенерирована таблица `PaymentParticipant`, с помощью которой в дальнейшем на основе поля `ObjectType` были сгенерированы таблицы `Supplier`, `Employee`, `Client`, `Cashbox`, `Bank`
- Имея соответствующие таблицы с участниками платежей была сгенерирована таблица с проектами
- В последнюю очередь была сгенерирована таблица с платежами

Пример работы генератора продемонстрирован в `Data-Generation-And-Test-Balance.ipynb`.

Также были проведены следующие исследования по генерации данных:

 - Пробовали менять размер пакетов с экспоненциальным увеличением числа записей.
     - Результаты показали, что размер пакета влияет на скорость выполнения при общем большом количестве записей в запросе вставки. Таким образом, чем больше размер одного пакета, тем быстрее проходит запрос. Эффект усиляется с увеличением общего размера запроса.
     - Сами результаты замеров можно найти в `logs.txt`, скрипт для замеров `indicies_chunks.py`

 - Пробовали добавить мультипроцессинг для замера производительности генерации.
     - Сначала столкнулись с deadlock'ом операции `SELECT` и `INSERT` (обновления `Payment` и просмотра `PaymentParticipant`) нескольких процессов.
     - В качестве решения проблемы был использован hint `UPDLOCK`. Это гарантирует, что `SELECT` использует блокировку записи вместо блокировки чтения, что предотвратит эскалацию блокировки между параллельными транзакциями.
     - Результаты расположены в `logs_multiprocessing.txt`, а скрипт для генерации `indicies_multiprocessing.py`. Скорость оказалась ожидаемо меньше последовательного варианта в силу блокировок.


### Разработать простой тест на корректность расчёта баланса
Данный тест был реализован на основе сценария описанного в `Balance description.pdf`. Пример работы данного теста продмемонстрирован в файле `Data-Generation-And-Test-Balance.ipynb`, поскольку, не были найдены альтернативы `tSQLt` для Linux систем.

## Задачи I уровня
 - Пробовали добавлять индексы для полей, которые используются в операциях:
    - `CalculateBalanceByMaterial`
    - `CalculateRemainderTheAdvance`
    - `CalculatePaymentParticipantBalance`
    - `CalculateBalanceByWork`
    - `CalculateProjectBalance`
    Результаты находятся в файле `logs_generated.txt`, а скрипт - `indicies_chunks_generated.py`. Данные результаты были полученные для вставки 100, 1000 и 3000 записей в таблицу `Payment` соответственно.
    По полученным значениям можно судить, что добавленные индексы практически не повлияли на производительность базы данных, поскольку отклонения от результатов для изначальных индексов незначительные и происходят как в отрицательную, так и в положительную сторону.
    Также был выполнен тест со вставкой 10000 записей (который продмемонстрирован в `Data-Generation-And-Test-Balance.ipynb`). Данный тест показал, что добавление индексов улучшило производительность вставки (750 и 664 секунд соответственно). Однако сложно судить о приросте качества, поскольку, по сравнению с тестами на 100, 1000, 3000 записей, замеры которых были усреднены по нескольким запускам, для теста на 10000 вставок был выполнен только один запуск.


## Задачи II уровня
1. Профилирование запросов было выполнено в `Azure Data Studio`. Результаты показали, что в среднем на выполнение триггера `T_Payment_AI`, срабатывающего после вставки или изменения платежа уходит 82% времени, триггер `T_Project_BU` срабатывающий до внесения правок в таблицу `Project` занимает 15% времени, а на триггер `T_PaymentParticipant_BU` уходит лишь 3% времени.
